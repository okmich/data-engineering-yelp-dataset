hdp.sources = src1
hdp.channels= chanl1 chanl2
hdp.sinks = snk1

#configure the source (note that this is for simulating the ingestion of data)
#in a real world deployment, you might be using other kinds of sources
hdp.sources.src1.type = spooldir
hdp.sources.src1.channels = chanl1
hdp.sources.src1.spoolDir = /home/cloudera/dataset/t-drive-trajectory-data-sample

#configure the first channel
hdp.channels.chanl1.type = memory

#configure the second channel (kafka channel)
#note that this will require a running instance of kafka with the topic 'data-transfer' to work
hdp.channels.chanl2.type= org.apache.flume.channel.kafka.KafkaChannel
hdp.channels.chanl2.kafka.bootstrap.servers=localhost:9092
hdp.channels.chanl2.kafka.topic= data-txnsfer
hdp.channels.chanl2.kafka.consumer.group.id = consumer-processing-1

#configure the hdfs sink
hdp.sinks.snk1.type=hdfs
hdp.sinks.snk1.channel=chanl1
hdp.sinks.snk1.hdfs.path=/user/cloudera/output/flume/sfp_solution1
hdp.sinks.snk1.hdfs.batchSize=1500
hdp.sinks.snk1.hdfs.rollSize=134217728
hdp.sinks.snk1.hdfs.rollInterval=3600
hdp.sinks.snk1.hdfs.rollCount=0
hdp.sinks.snk1.hdfs.fileType=DataStream
hdp.sinks.snk1.hdfs.writeFormat=Text